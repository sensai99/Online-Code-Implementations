{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "2t6RJfJyCIO4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWyTDYyHB6Xb",
        "outputId": "a83cadf0-32e4-408a-de85-8c860963bd09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtransformers==4.56.2                                                          \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtrl==0.22.2                                                                   \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtokenizers==0.22.1                                                            \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2munsloth==2025.11.3                                                            \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2munsloth-zoo==2025.11.3                                                        \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m5 packages\u001b[0m \u001b[2min 18ms\u001b[0m\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m5 packages\u001b[0m \u001b[2min 0.43ms\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os, importlib.util\n",
        "\n",
        "!pip install --upgrade -qqq uv\n",
        "\n",
        "if importlib.util.find_spec(\"torch\") is None or \"COLAB_\" in \"\".join(os.environ.keys()):\n",
        "    try: import numpy, PIL; get_numpy = f\"numpy=={numpy.__version__}\"; get_pil = f\"pillow=={PIL.__version__}\"\n",
        "    except: get_numpy = \"numpy\"; get_pil = \"pillow\"\n",
        "    !uv pip install -qqq \\\n",
        "        \"torch>=2.8.0\" \"triton>=3.4.0\" {get_numpy} {get_pil} torchvision bitsandbytes \"transformers==4.56.2\" \\\n",
        "        \"unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo\" \\\n",
        "        \"unsloth[base] @ git+https://github.com/unslothai/unsloth\" \\\n",
        "        git+https://github.com/triton-lang/triton.git@05b2c186c1b6c9a08375389d5efe9cb4c401c075#subdirectory=python/triton_kernels\n",
        "elif importlib.util.find_spec(\"unsloth\") is None:\n",
        "    !uv pip install -qqq unsloth\n",
        "\n",
        "!uv pip install --upgrade --no-deps transformers==4.56.2 tokenizers trl==0.22.2 unsloth unsloth_zoo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "7P6BB-CFFMcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from transformers import TextStreamer"
      ],
      "metadata": {
        "id": "UWusKonJCLRa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "_QbxUJloFLJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 1024\n",
        "dtype = None\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MODEL_NAME = \"unsloth/gpt-oss-20b\"\n",
        "\n",
        "# Define and load the base model\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = MODEL_NAME,\n",
        "    dtype = dtype,\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True,\n",
        "    full_finetuning = False\n",
        ")\n",
        "\n",
        "# Add lora adapters for PEFT\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 8,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None\n",
        ").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491,
          "referenced_widgets": [
            "711465ac48d9493a842e7cb7d16f3778",
            "f4563d1c9d314ee6ac8beaca5bdc0594",
            "369d1492bd4146368431c69e99a53f17",
            "5b95310f3bd849b1a93bf9bcba7b6c45",
            "f149c426febf4cdca13c1f1d34f4309c",
            "8cfe2fcd27604bb8b93d5127aa928cec",
            "2ed6fe725eae4c2aa31f348ea4ee08b2",
            "676a236c5d4f430da127bc5eeaa701cd",
            "d3f5f337dad74d1096c7d48f1eebd94c",
            "2623492d8dfb4f0d9e696a226a636ee0",
            "753b31a56018440caeffe167709af323",
            "3d7c2dd879f34307ace43cc0b9cb6507",
            "1d6340dbb0a2474bb3f5983a08ca6fa8",
            "37ac6eb116d94b1bad0ac51cfdca580a",
            "09df4efe74f74413b4f1081dedca1fdc",
            "f77d5fade0e14bd08c780b1fbec406c2",
            "a4d3cd7280b440d09ee92bfde32c17bb",
            "18809a6d751647adbe7844ca4eae5148",
            "a2df551df0fe4996baa1394878e8008a",
            "b0b3fc0934ac460d839b612c11afdbee",
            "e1d222db725847e79de4150974c3815d",
            "ba294f28a918495780ba1d3ef1ff0521",
            "459abade89714a7a855e41ecb2033091",
            "fe055883e38a43d3a12a7dbf8feb9bb5",
            "a3b33913c1744cedbc25db4ffb5d3322",
            "ffa4707b1bc94d6989f85d1e529bc751",
            "799fbf4b1cec4fb790ba63c43036022d",
            "a87c54abe6754acba5c6bafa34a0c328",
            "271cad23b22c4484bda9a1afe173a442",
            "d72def9ecb1b4aac9ec8f104d9e17693",
            "51cfa0803b654a6f9447bd97f3d5db8f",
            "7a3927c86f8340848ae6d61ea28dbf47",
            "b866fdef050444b99ef73dc248145b4b",
            "96acb2d227b14a399106d4a5d6cd8c0b",
            "18cf82f5105c4306aef23e8f22da9067",
            "a039652d86ce4e819605cd8e04f65d05",
            "312d6688645844909aa713bafe16b0c0",
            "56af1850ad1e47ac89937f8b74a14bc3",
            "bde100c480a84e04bdf4f941ef74aefa",
            "c6d8c4eab9e5453283133ff547ee2890",
            "584a02a791e4457588cddbc5e7cf8484",
            "294efda44d2b473b815bf5ba75171970",
            "a202358d89fb4434b2278ea8f24d9f8a",
            "b41aff99d1d24f3cbcf6d171a200d88c",
            "0d46781e7333492982751bcecb3bfee1",
            "98a6f6cc148b4f608ee1ede1e0ff1335",
            "d146972c3d0e451aa1c84f7fd45c5f2d",
            "9937d6db348c44d0b8dfcceb95af4b18",
            "3f550d693dc0487490a4be4131784c5d",
            "8d33bd72bf364833a3445c24b0c9db43",
            "7ef34b9c55bc45d29e0cee845a711615",
            "c4fa105807c146729ecd97e90b838c2d",
            "a8fde9783b1d453d92bb1d6dd0bb3555",
            "be1a4bfc0dcd40ca85bec21abfd542b9",
            "22fc1753554b48599f013e1875237ea1",
            "e0697afa82d34e88aee81a133d8fa34b",
            "f87dd6a0c956479d87121b906193ea86",
            "51ab1fb777964dba9d3c77606f42bd05",
            "7b62b88ec54f47369ac6f3b24fdb9838",
            "763527c222a941dead8d8766181b3dc6",
            "0c2e4e69c0b2426ca204177405e726af",
            "0842b32ccb1b421dbbb2fd24a76d0083",
            "287e421b86f8457fa70c62096dcb9910",
            "9e424b3975fc403698cee6253cbda0cc",
            "2112c33c4a4c4b2c8875e054b4387ee8",
            "d72bcdebbaa44693bcdf488d454507f1",
            "92220849072b4f2992da5dbe125c673a",
            "07d0f458005f4a35b04a606fb3ee522d",
            "ad201e1906f44f15bb8e9ce6e5e166f5",
            "a90d1a4e972745a3a8006340df28f031",
            "6a8602499440498293e44027a9dba0ad",
            "231d45dc6b2544c28b580b3b7a4f24e7",
            "cdd042d7aabd47479ac61ea2539f9980",
            "d9ae21f431454bf5ae8813935a943327",
            "2f54db0e30354074a15abf9dbd374233",
            "8a29719c80a548359cb350e28a4bb7c8",
            "2c7c3045ce71497bb592f2d22650c922",
            "039de995298e444e95225c2ffb0338d2",
            "51171b037d884e6cb5ad3da3c48cd5cf",
            "dffe60fc3a8245a4a5f94242d88105b8",
            "449c31efdf2041a7ade6a811ac6a90c8",
            "d0a3373eb9c64f28a00f15ad559cff11",
            "b4db4a8e4c0a41cfb833001e78c5f3c6",
            "411ec3e93fc840029141b98494c21101",
            "42711bddad0f4b61ac207af67cef52f6",
            "6966eae19f0240c88edbe52437e678e2",
            "6249fcf43b9d4681b36b136e4f1c74bd",
            "cab209f5a7a94670b51477b17dd50e3d",
            "f62a8b39387b441889274a412d9f1119",
            "6821a82049a447e4afad238c6a828d75",
            "120788066b534af79939327d12432288",
            "10d3fae45e9a455b93ec3d3d9aa0c192",
            "52fde9b1d4dd4931bb3682fa2309d2bf",
            "60a7083d28e6412db2f6914b293b9d61",
            "17eef45161ad4912a999b62259210fcc",
            "1cdd1fdf6a0f45ccaa836d5b4f828782",
            "dad6028f7ed74f7abc490c2b0408fe37",
            "856331938b4d426caf5f2c5be2f3e5dd",
            "bc7b2f9d9c554833b4a95d68943c1cf3",
            "38418cfa44d94808a4158b74a173576f",
            "e23704950a034e5f80461e6825e33a6b",
            "1ebc46677db440ce9d98d7b260ef420a",
            "50c57d6cad2c43a28a566499e09e10e4",
            "c58c335fdb78445381c2ecba07307778",
            "3f2e9986b1e248cd8a3115e917c4b225",
            "5d1d6348f22b4bbb85dd4aec0cf41505",
            "2987fc02a828471999cd6673597748a3",
            "774fc4f6bb994581a583866d64af2613",
            "ddc5de5885254ae58d19433a58d3e872",
            "9cb4e12ec3cd4f968f09d191ab8b05f9",
            "1930cf96987e4121aa16fae9d2fb0f13",
            "767c4fc2400f44e0bdde94b79bdcd7da",
            "48323c96f11c44b4b5fe761db617b97f",
            "ff24f13aaf0048d4913fa1b687884ccb",
            "b0c1db678d3c41a996440bd0eeb8ed5b",
            "ee78e2cc4f5f4c298bfaf2bea94b03cf",
            "05504b548a2d4ff9bd31825573c7c5b8",
            "71887599694a4ab8aa3bc3d720fb5f69",
            "3015243165d643c68fa486142e7d189d",
            "36be3aa9ae9448558e5132d1942c2a38",
            "af9613867b814e8eac0b4e3eef224a50"
          ]
        },
        "id": "AGcjEhteCPpo",
        "outputId": "9e5723f3-5580-4ed8-ff66-57d80d324917"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.11.3: Fast Gpt_Oss patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "711465ac48d9493a842e7cb7d16f3778"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d7c2dd879f34307ace43cc0b9cb6507"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "459abade89714a7a855e41ecb2033091"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/3.37G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96acb2d227b14a399106d4a5d6cd8c0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.16G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d46781e7333492982751bcecb3bfee1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0697afa82d34e88aee81a133d8fa34b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/165 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92220849072b4f2992da5dbe125c673a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "039de995298e444e95225c2ffb0338d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/27.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f62a8b39387b441889274a412d9f1119"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/446 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38418cfa44d94808a4158b74a173576f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.jinja: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1930cf96987e4121aa16fae9d2fb0f13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Making `model.base_model.model.model` require gradients\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inputs"
      ],
      "metadata": {
        "id": "MWXuW_1pNw74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What is 78645 * 1290?\"}\n",
        "]"
      ],
      "metadata": {
        "id": "UtSlwFx_NzdL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True,\n",
        "    tokenize = False\n",
        ")\n",
        "raw_inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nXZsuo-oNwgs",
        "outputId": "067f7d4a-3beb-4b7b-eda8-f4615dc8235e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\\nKnowledge cutoff: 2024-06\\nCurrent date: 2025-11-12\\n\\nReasoning: medium\\n\\n# Valid channels: analysis, commentary, final. Channel must be included for every message.\\nCalls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>user<|message|>What is 78645 * 1290?<|end|><|start|>assistant\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference test\n",
        "\n",
        "# Converts messages into LLM understandable format i.e. \"<start> <role> <message> ...\"\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True, # adds the special token at the end indicating it's model's turn\n",
        "    return_tensors = \"pt\",\n",
        "    return_dict = True,\n",
        "    reasoning_effort = \"low\" # reasoning intensity - low for easy and high for complex queries\n",
        ").to(device) # defaults to CPU, need to move to GPU\n",
        "\n",
        "# Notes:\n",
        "# 1. Changing the roles in messages might lead to unpredictable outputs (i.e. \"assistant\" in place of \"user\")"
      ],
      "metadata": {
        "id": "vUWdYveUCW35"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = model.generate(**inputs, max_new_tokens = 128, streamer = TextStreamer(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc9J6f7XHgpP",
        "outputId": "3f0e5080-b604-4b28-b9a1-d9f7e98885ca"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\n",
            "Knowledge cutoff: 2024-06\n",
            "Current date: 2025-11-12\n",
            "\n",
            "Reasoning: low\n",
            "\n",
            "# Valid channels: analysis, commentary, final. Channel must be included for every message.\n",
            "Calls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>user<|message|>What is 78645 * 1290?<|end|><|start|>assistant<|channel|>analysis<|message|>We need to compute 78645 * 1290. 78645*1000=78,645,000. 78645*200=15,729,000. 78645*90=7,078,050? Wait 78645*90=7,078,050 (yes). Sum: 78,645,000+15,729,000=94,374,000. Add 7,078,050=101,452,050. Check: 78645*(1000+200+90)=78645*1000+78645*200+78645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ASlrZf9Hj0M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}